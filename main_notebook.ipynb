{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from conversation import create_coder, create_reviewer, create_refiner, start_conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de RL - Qual o Melhor Prompt para Iterar sobre a Geração de Código?\n",
    "Nosso trabalho de RL é sobre descobrir quais os melhores prompts para iterar sobre a geração de \n",
    "código de LLMs.\n",
    "\n",
    "## Como funciona\n",
    "Criamos uma conversa com 3 participantes: Coder, Reviewer e Refiner.\n",
    "Cada participante é responsável por enviar um prompt para o LLM, e inputar os resultados do LLM no\n",
    "ambiente (aqui chamado de 'conversa').\n",
    "\n",
    "### Coder\n",
    "O Coder é responsável por escrever o código.  \n",
    "Ele envia o prompt inicial, descrevendo o problema a ser resolvido. Definimos que todos os nossos\n",
    "problemas serão de limpeza de uma base de dados csv.  \n",
    "O Coder só participa da conversa 1 vez (no início) e, por isso, não o definimos como um agente RL.\n",
    "Ao invés disso, ele é programado para iterar por todos os prompts n vezes, e avaliamos os resultados\n",
    "das conversas com cada prompt inicial posteriormente.\n",
    "\n",
    "### Reviewer\n",
    "O Reviewer é responsável por avaliar o código gerado pelo LLM.  \n",
    "Ele envia um prompt solicitando a avaliação do código gerado pelo LLM. Ele pode essa avaliação\n",
    "sempre após a geração de um código que não tem nota superior à nota terminal.  \n",
    "O Reviewer é um agente RL, e seu objetivo é maximizar a nota do código gerado pelo LLM.\n",
    "\n",
    "### Refiner\n",
    "O Refiner é responsável por refinar o código gerado pelo LLM.\n",
    "Ele envia um prompt solicitando a melhoria do código gerado pelo LLM. Ele pode essa avaliação\n",
    "sempre após uma revisão do Reviewer.  \n",
    "O Refiner é um agente RL, e seu objetivo é maximizar a nota do código gerado pelo LLM.\n",
    "\n",
    "### Prompt\n",
    "Para cada participante, geramos prompts que iam de 1 a $n$ nas **escalas** das seguintes **propriedades**:\n",
    "- Clareza;\n",
    "- Comprimento;\n",
    "- Especificidade, e\n",
    "- Complexidade.\n",
    "\n",
    "Isso totalizou até 20 prompts diferentes para cada participante. Para diminuir o espaço de ações,\n",
    "optamos por usar uma estratégia mais simples:\n",
    "\n",
    "- Para cada prompt (**comprimento da escala** x **número de propriedades**) do **Coder**;\n",
    "    - Para cada **propriedade** do **Reviewer**;\n",
    "        - Para cada **propriedade** do **Refiner**;\n",
    "            - Geramos $m$ conversas onde:\n",
    "                1. O Coder envia o prompt e adiciona o código inicial;\n",
    "                2. O código é avaliado (se a nota não for terminal, prossegue);\n",
    "                3. O Reviewer escolhe um dos $n$ prompts da **propriedade** e adiciona a revisão;\n",
    "                4. O Refiner escolhe um dos $n$ prompts da **propriedade** e adiciona a melhoria.\n",
    "                5. Se o comprimento da conversa não for terminal, volta ao passo 2.\n",
    "\n",
    "### Avaliação do Código\n",
    "O código é avaliado por um LLM usando a bibliteca `instructor`. Pedimos que o código receba uma nota\n",
    "de 0 a 100 para a sua corretude e legibilidade, bem como uma curta explicação do porquê da nota \n",
    "(esse comentário é adicionado posteriormente à conversa).  \n",
    "Se a nota média for superior a 95, a conversa é terminada pois consideramos que o código é bom o\n",
    "suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with JSON files name\n",
    "json_files_coder = [\n",
    "    \"json_files/prompts_clarity_coder.json\",\n",
    "    \"json_files/prompts_size_coder.json\",\n",
    "    \"json_files/prompts_specificity_coder.json\",\n",
    "    \"json_files/prompts_complexity_coder.json\"\n",
    "]\n",
    "\n",
    "json_files_reviewer = [\n",
    "    \"json_files/prompts_clarity_reviewer.json\",\n",
    "    \"json_files/prompts_size_reviewer.json\",\n",
    "    \"json_files/prompts_specificity_reviewer.json\",\n",
    "    \"json_files/prompts_complexity_reviewer.json\"\n",
    "]\n",
    "\n",
    "json_files_refiner = [\n",
    "    \"json_files/prompts_prop1_refiner.json\",\n",
    "    \"json_files/prompts_prop2_refiner.json\",\n",
    "    \"json_files/prompts_prop3_refiner.json\",\n",
    "    \"json_files/prompts_prop4_refiner.json\"\n",
    "]\n",
    "\n",
    "prompts_coder = []\n",
    "for file_name in json_files_coder:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        for i, item in enumerate(data):\n",
    "            item[\"index\"] = i\n",
    "        prompts_coder += data\n",
    "\n",
    "reviewer_properties = {}    \n",
    "for file_name in json_files_reviewer:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        for item in data:\n",
    "            if item[\"propriedade\"] not in reviewer_properties:\n",
    "                reviewer_properties[item[\"propriedade\"]] = []\n",
    "            reviewer_properties[item[\"propriedade\"]].append(item['prompt'])\n",
    "\n",
    "refiner_properties = {}\n",
    "for file_name in json_files_coder:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        for item in data:\n",
    "            if item[\"propriedade\"] not in refiner_properties:\n",
    "                refiner_properties[item[\"propriedade\"]] = []\n",
    "            refiner_properties[item[\"propriedade\"]].append(item['prompt'])                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Coder Prompt Index: 1\n",
      "Random Reviewer Prop: size\n",
      "Random Refiner Prop: complexity\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Choose a random coder prompt\n",
    "random_coder_prompt = random.choice(prompts_coder)\n",
    "\n",
    "# Choose a random reviewer prompt\n",
    "random_reviewer_prop = random.choice(list(reviewer_properties.keys()))\n",
    "random_reviewer_prompt = reviewer_properties[random_reviewer_prop]\n",
    "\n",
    "# Choose a random refiner prompt\n",
    "random_refiner_prop = random.choice(list(refiner_properties.keys()))\n",
    "random_refiner_prompts = refiner_properties[random_refiner_prop]\n",
    "\n",
    "print(\"Random Coder Prompt Index:\", random_coder_prompt[\"index\"])\n",
    "print(\"Random Reviewer Prop:\", random_reviewer_prop)\n",
    "print(\"Random Refiner Prop:\", random_refiner_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Initial prompt**: Can you provide me with Python code that cleans up a dirty CSV file? The code should use the 'pandas' and 'numpy' libraries. It would be helpful if it included some basic cleaning steps like handling missing values, converting formats to correct types, and checking for inconsistencies in the data. Please focus on creating a concise and well-structured script that showcases best practices.\n",
       "\n",
       "Here is the `imdb_sample_10.csv` file content:\n",
       "\n",
       "Series_Title,Released_Year,Runtime,Genre,IMDB_Rating,Meta_score,Director,No_of_Votes\n",
       "The Shawshank Redemption,1994,,Drama,nan,nan,,nan\n",
       ",1972,,\"Crime, Drama\",nan,nan,,nan\n",
       "The Dark Knight,,,\"Action, Crime, Drama\",,,Christopher Nolan,\n",
       "The Godfather: Part II,nan,,\"Crime, Drama\",9.0,90.0,Francis Ford Coppola,nan\n",
       ",1957,,\"Crime, Drama\",9.0,96.0,Sidney Lumet,nan\n",
       "The Lord of the Rings: The Return of the King,2003,201 min,,8.9,94.0,Peter Jackson,nan\n",
       ",,154 min,\"Crime, Drama\",,,,\n",
       "Schindler's List,,195 min,,,,,\n",
       "Inception,,148 min,\"Action, Adventure, Sci-Fi\",,,Christopher Nolan,\n",
       "Fight Club,nan,139 min,Drama,8.8,66.0,David Fincher,nan\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Coder**: ```python\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "\n",
       "# Load the CSV file into a Pandas DataFrame\n",
       "df = pd.read_csv(\"imdb_sample_10.csv\")\n",
       "\n",
       "# Check for missing values and handle them appropriately\n",
       "print(df.isnull().sum())  \n",
       "\n",
       "# Convert columns to correct data types (example: replace 'nan' with NaN)\n",
       "df['IMDB_Rating'] = df['IMDB_Rating'].fillna(pd.NA) \n",
       "\n",
       "\n",
       "# Handle inconsistencies in the data, such as format errors and inconsistent entries\n",
       "# ... Add your custom cleaning code here ...\n",
       "\n",
       "\n",
       "# Print the cleaned DataFrame to verify the results\n",
       "print(df.head())  \n",
       "\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "1. **Import Libraries:** The first line imports the necessary libraries (`pandas` for data manipulation and `numpy` for numerical operations). \n",
       "2. **Load CSV File:**  `pd.read_csv(\"imdb_sample_10.csv\")` reads the CSV file into a Pandas DataFrame, which is a more suitable format for data analysis than a plain list. \n",
       "3. **Check for Missing Values (Optional):** The code uses `df.isnull().sum()` to identify and count missing values in each column. \n",
       "4. **Convert Data Types:**  This example replaces 'nan' with the default NaN representation from Pandas (`pd.NA`). You might use other methods based on your data's context, such as:\n",
       "    - Converting strings to numerical using `pd.to_numeric()` if you expect numeric values in a column. \n",
       "    - Replacing specific entries or converting to appropriate data types (e.g., dates).\n",
       "\n",
       "5. **Handle Inconsistencies:** You can add your custom code here to address inconsistencies such as:\n",
       "   - **Format Errors:** If there's inconsistent formatting, like strings being dates, numbers or different characters, you need to convert them to the correct format (using `str` functions) and check for any errors. \n",
       "   - **Inconsistency in Values:**  Check for values that are out of range (e.g., extremely high ratings) and determine if they should be replaced or adjusted based on your criteria. \n",
       "\n",
       "\n",
       "6. **Print Results:** The `df.head()` function shows the first few rows of the cleaned DataFrame, allowing you to confirm the results.\n",
       "\n",
       "**Important Notes:**\n",
       "\n",
       "* **Custom Cleaning:** This code provides a starting point for cleaning your CSV file. You'll need to customize it based on the specific issues in your data and the requirements of your project (e.g., what inconsistencies are causing problems).  \n",
       "* **Data Analysis Libraries:** If you have more complex cleaning needs, consider using libraries like `numpy` or `scikit-learn`. \n",
       "\n",
       "\n",
       "Let me know if you want to learn about any specific aspect of the cleaning process or need help applying custom fixes to your data!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/markdown": [
       "**Code Grade**: **Correctness:** 80\n",
       "\n",
       "**Grade Explanation:** The code demonstrates a solid understanding of necessary preprocessing steps for a dataset. Notably, it utilizes both Pandas for file handling and its inherent functions  like `isnull()` and  `fillna()`. It clearly explains the importance of handling missing values  and inconsistent entries (though this could be enhanced by specific examples about how they are addressed). \n",
       "\n",
       "**Readability:** 75\n",
       "\n",
       "**Grade Explanation:** The code is mostly readable, employing clear comments and indentation.  It demonstrates a focus on producing cleaned data for further analysis. However, the user can benefit from more robust explanations of techniques such as removing outliers or handling data based on specific rules."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Reviewer**: ## Python Script Review: Cleaning a CSV Database\n",
       "\n",
       "Here's an analysis of the provided code snippet for cleaning a CSV database, focusing on structure, logic, and potential areas for improvement. \n",
       "\n",
       "\n",
       "**Structure & Logic:**\n",
       "\n",
       "* **Strengths:** The code is structured clearly, with imports, data loading, missing value handling, and data type conversion steps in separate blocks. This promotes readability and modularity.  \n",
       "    * **Example:** Using `df.isnull().sum()`, the user can easily identify missing values, and its presence facilitates further data cleaning and analysis.  \n",
       "\n",
       "* **Potential Improvements:** \n",
       "   -  **Code Organization:** While the structure is clear, it might benefit from a more structured approach, like using functions for specific tasks to make the code easier to understand and maintain.\n",
       "   \n",
       "**Data Processing Logic:**\n",
       "\n",
       "* **Strengths:** The script effectively addresses common data cleaning needs:\n",
       "    -  **Checking for missing values:**  `df.isnull().sum()` provides quick insights into missing value occurrences. \n",
       "    - **Missing Value Handling:** Replacing `nan` with `pd.NA` is a standard practice in data analysis, ensuring consistency and accuracy.\n",
       "    \n",
       "* **Potential Improvements:** \n",
       "   - **Handling Data Inconsistency:** The current code focuses on missing values. However, to efficiently deal with inconsistencies such as date format, inconsistent entry types, etc., you might benefit from adding checks and specific actions based on your dataset's context. For instance, consider: \n",
       "      *  Replacing dates with a uniform format using `pd.to_datetime()`\n",
       "      *  Converting strings to numeric values if they represent quantities \n",
       "\n",
       "**Efficiency & Best Practices:**\n",
       "\n",
       "* **Strengths:** The code is efficient and easy to understand. It employs Pandas' built-in functions, making it fast and reliable.\n",
       "\n",
       " * **Potential Improvements:** \n",
       "   - **Preprocessing before Cleaning:** Depending on the scope of your cleaning, you might benefit from pre-processing steps (e.g., header extraction or data standardization) before starting the actual cleaning process.  This helps to focus on the specific actions required for each step. \n",
       "\n",
       "\n",
       "**Clarity & User Experience:**\n",
       "\n",
       "* **Strengths:**  The code is written in a clear and concise manner, making it easy to follow and understand. Use of `df.head()` provides quick visual feedback on progress.\n",
       "   \n",
       "* **Potential Improvements:**  Comments can provide further context about the cleaning steps performed for specific tasks. Adding detailed explanations of the `fillna()` method and data type conversion techniques would benefit users unfamiliar with these operations.\n",
       "\n",
       "**Overall:** \n",
       "\n",
       "\n",
       "The code demonstrates a good understanding of basic data cleaning principles. However, incorporating more comprehensive functionalities like data type validation and custom handling of inconsistencies will increase its robustness and user experience. The use of functions for specific tasks would further improve readability and maintainability.  \n",
       "\n",
       "\n",
       "\n",
       "**Recommendations:** \n",
       "* **Modularization:** Encapsulate specific cleaning steps into separate functions to make the code easier to read and maintain. \n",
       "* **Comments:** Explain the reasoning behind your decisions when implementing changes. \n",
       "\n",
       "By incorporating these recommendations, you can create a more comprehensive and efficient script for cleaning your CSV database!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Code Refiner**: Here's a Python code snippet showcasing how to clean your CSV file using Pandas:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "# Load the CSV file into a DataFrame \n",
       "df = pd.read_csv(\"your_data.csv\")  \n",
       "\n",
       "# Handle Missing Values\n",
       "# Example: Replace missing values in 'Age' column with the mean\n",
       "df['Age'].fillna(df['Age'].mean(), inplace=True)  \n",
       "\n",
       "\n",
       "# Remove Empty Rows\n",
       "# Example: Remove rows with all NaN values\n",
       "df.dropna(inplace=True) \n",
       "\n",
       "# Convert Data Types (Optional)\n",
       "# Example: Convert 'Date' to datetime format\n",
       "df['Date'] = pd.to_datetime(df['Date'])  \n",
       "\n",
       "print(df.head())\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "1. **Importing Pandas:** `import pandas as pd` imports the Pandas library for data manipulation and analysis. \n",
       "2. **Loading Data:** `df = pd.read_csv(\"your_data.csv\")` reads your CSV file into a Pandas DataFrame (a table-like structure). Replace `\"your_data.csv\"` with the actual path to your file.  \n",
       "\n",
       "3. **Handling Missing Values:**\n",
       "   * We use the `.fillna()` method: \n",
       "      * `df['Age'].fillna(df['Age'].mean(), inplace=True)` replaces missing values in the 'Age' column with the average age of the non-missing values (using the mean). You can replace this with strategies like:\n",
       "         * **Forward Fill:** Filling with the next value if it exists \n",
       "         * **Backward Fill:** Filling with the previous value.\n",
       "  \n",
       "4. **Removing Empty Rows:**  `df.dropna(inplace=True)` removes rows that have all `NaN` (Not a Number) values in any column. This is useful to remove empty data entries.\n",
       "\n",
       "5. **Converting Data Types:** The `pd.to_datetime()` function helps convert a string column representing dates or times into datetime format, allowing for easier analysis and manipulation of this information. \n",
       "\n",
       "\n",
       "**Example Usage:**  \n",
       "Let's assume your CSV file has data like this:\n",
       "```csv\n",
       "Name,Age,Date\n",
       "Alice,25,2023-10-26\n",
       "Bob,30,None\n",
       "Charlie,28,2023-10-27\n",
       "David,None,2023-10-28\n",
       "Emily,40,2023-10-29\n",
       "```\n",
       "\n",
       "After running the code, you would get a cleaner DataFrame (the output will look different depending on your specific data).\n",
       "\n",
       "\n",
       "\n",
       "**Key Points:**  \n",
       "\n",
       "* **Data Cleaning is Essential:** Before diving into analysis, cleaning up the raw data ensures accuracy and helps avoid bias.\n",
       "* **Flexibility:** Pandas offers various techniques for handling missing values like `fillna()` or `interpolate()`. \n",
       "\n",
       "\n",
       "Let me know if you have a specific dataset and challenges, and I can provide more tailored code examples! "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from rl.code_evaluator import CodeEvaluator\n",
    "\n",
    "\n",
    "MAX_TURNS = 1\n",
    "coder = create_coder(prompts_coder)\n",
    "\n",
    "coder_prompt_dict = random_coder_prompt\n",
    "reviewer = create_reviewer(random_reviewer_prompt)\n",
    "refiner = create_refiner(random_refiner_prompts)\n",
    "evaluator = CodeEvaluator(environment=None, prompt=\"Evaluate the code quality\", name=\"Code Evaluator\")           \n",
    "            \n",
    "environment = start_conversation(\n",
    "    coder, \n",
    "    coder_prompt_dict, \n",
    "    reviewer, \n",
    "    refiner, \n",
    "    MAX_TURNS\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
